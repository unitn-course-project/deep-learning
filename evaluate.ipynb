{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "evaluate.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unitn-course-project/deep-learning/blob/main/evaluate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxdfhZ23CZgD"
      },
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksougSrrCxZq",
        "outputId": "d6278330-3f03-4790-bee3-801cb5a1842b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "import sys\n",
        "sys.path.insert(0, '/content/drive/MyDrive/DeepLearning/')\n",
        "from loading_data import *\n",
        "from model import *"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFG0ATj2B6RF",
        "outputId": "d9e6c0d9-3d09-48c7-f849-3491aec234a8"
      },
      "source": [
        "transform = list()\n",
        "transform.append(transforms.ToTensor())\n",
        "transform.append(transforms.Normalize(mean=[0.5], std=[0.5]))\n",
        "transform = transforms.Compose(transform)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "PATH = \"/content/drive/MyDrive/DeepLearning/checkpoint/model_VGG16_original.pt\"\n",
        "with torch.no_grad():\n",
        "  full_test_data = PedestrianDataset(\"/content/drive/MyDrive/DeepLearning/datasets/annotations_train_v2.csv\", \"/content/drive/MyDrive/DeepLearning/datasets/val_attr\", transform)\n",
        "  test_loader = torch.utils.data.DataLoader(full_test_data, 32, shuffle=False)\n",
        "  net = initialize_vgg16(32).to(device)\n",
        "  # net = VGG16().to(device)\n",
        "  if device == torch.device(\"cpu\"):\n",
        "      checkpoint = torch.load(PATH, map_location=torch.device('cpu'))\n",
        "  else:\n",
        "    checkpoint = torch.load(PATH)\n",
        "  net.load_state_dict(checkpoint['model_state_dict'])\n",
        "  net.eval()\n",
        "  cumulative_accuracy = torch.zeros(32).to(device)\n",
        "  with tqdm(total=len(test_loader)) as pbar:\n",
        "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)    \n",
        "      outputs = net(inputs)\n",
        "      predicted = outputs > 0.5\n",
        "      acc = torch.sum(predicted.eq(targets),0)\n",
        "      cumulative_accuracy += acc\n",
        "      pbar.update(1)\n",
        "    print(cumulative_accuracy/len(full_test_data))\n",
        "    print(torch.mean(cumulative_accuracy/len(full_test_data)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 41/41 [02:11<00:00,  3.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([0.7308, 0.7562, 0.8862, 0.9177, 0.9108, 0.9362, 0.8292, 0.9723, 0.8523,\n",
            "        0.8615, 0.8954, 0.8954, 0.9646, 0.9208, 0.8854, 0.9115, 0.9238, 0.8685,\n",
            "        0.9315, 0.9631, 1.0000, 0.9915, 0.8454, 0.7985, 0.9723, 0.9185, 0.9908,\n",
            "        0.8408, 0.8654, 0.9846, 0.9169, 0.9500])\n",
            "tensor(0.9027)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM7ASSyBfT2u"
      },
      "source": [
        "scratch-> tensor([0.7308, 0.7562, 0.8862, 0.9346, 0.9215, 0.9362, 0.8823, 0.9723, 0.9162,\n",
        "        0.8615, 0.7200, 0.8954, 0.9646, 0.9208, 0.8854, 0.9115, 0.9238, 0.9192,\n",
        "        0.9315, 0.9631, 1.0000, 0.9915, 0.8454, 0.7985, 0.9723, 0.9185, 0.9908,\n",
        "        0.8885, 0.9023, 0.9846, 0.9169, 0.9500])\n",
        "tensor(0.9060)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krMYKqy7dLCF"
      },
      "source": [
        "origin -> tensor([0.7308, 0.7562, 0.8862, 0.9162, 0.9162, 0.9362, 0.7954, 0.9723, 0.8438,\n",
        "        0.8615, 0.8885, 0.8954, 0.9646, 0.9208, 0.8854, 0.9115, 0.9238, 0.8531,\n",
        "        0.9315, 0.9631, 1.0000, 0.9915, 0.8454, 0.7985, 0.9723, 0.9185, 0.9908,\n",
        "        0.8408, 0.8654, 0.9846, 0.9169, 0.9500])\n",
        "tensor(0.9008)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBhyu61IFf_n"
      },
      "source": [
        "agumented -> tensor([0.7308, 0.7562, 0.8862, 0.8600, 0.9215, 0.9362, 0.8985, 0.9723, 0.9269,\n",
        "        0.8615, 0.9323, 0.9838, 0.9646, 0.9208, 0.8854, 0.9115, 0.9238, 0.9162,\n",
        "        0.9315, 0.9631, 1.0000, 0.9915, 0.8454, 0.7985, 0.9723, 0.9185, 0.9908,\n",
        "        0.8662, 0.8808, 0.9846, 0.9169, 0.9500])\n",
        "tensor(0.9125)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "him5Gq47CBJd"
      },
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "transform = list()\n",
        "transform.append(transforms.ToTensor())\n",
        "transform.append(transforms.Normalize(mean=[0.5], std=[0.5]))\n",
        "transform = transforms.Compose(transform)\n",
        "\n",
        "full_training_data = datasets.ImageFolder('/content/drive/MyDrive/DeepLearning/datasets/val_iden/', transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(full_test_data, 32, shuffle=False)\n",
        "sample_image, sample_label = full_training_data[0]\n",
        "image = Variable(sample_image, requires_grad=True)\n",
        "activation = {}\n",
        "def get_activation(name):\n",
        "  def hook(model, input, output):\n",
        "    activation[name] = output.detach()\n",
        "  return hook\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "PATH = \"/content/drive/MyDrive/DeepLearning/checkpoint/model_iden_VGG16.pt\"\n",
        "with torch.no_grad():\n",
        "  net = initialize_vgg16(751).to(device)\n",
        "  net.classifier[3].register_forward_hook(get_activation('features'))\n",
        "  if device == torch.device(\"cpu\"):\n",
        "      checkpoint = torch.load(PATH, map_location=torch.device('cpu'))\n",
        "  else:\n",
        "    checkpoint = torch.load(PATH)\n",
        "  net.load_state_dict(checkpoint['model_state_dict'])\n",
        "  net.eval()\n",
        "  for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)    \n",
        "      outputs = net(inputs)\n",
        "  # output = net(image)\n",
        "      print(\"feature\", len(activation['features']), len(activation['features'][0]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}